% -*- mode: latex; mode: flyspell; mode: auto-fill -*-

\documentclass[12pt,onecolumn]{memoir}
\usepackage[english,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage[hyperindex,backref,bookmarks,linktocpage]{hyperref}

\usepackage[T1]{fontenc}

\usepackage{textcomp}
\usepackage[sc]{mathpazo}
\usepackage{helvet}
\linespread{1.05} % Palatino needs more leading (space between lines)

\usepackage{enumerate}
\usepackage{epsfig}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color}
\usepackage{setspace}
\usepackage{rotating}
\usepackage{colortbl}
\usepackage{tikz}
\usepackage{framed}

\definecolor{goldenpoppy}{rgb}{0.99, 0.86, 0.3}
\definecolor{dark-green}{rgb}{0,0.5,0}
\definecolor{metallic-green}{rgb}{0.75,0.81,0.58}
\definecolor{dark-red}{rgb}{0.5,0,0}

\newenvironment{ejercicio}{%
    \def\FrameCommand{\fboxrule=\FrameRule\fboxsep=\FrameSep \fcolorbox{black}{metallic-green}}%
    \MakeFramed {\FrameRestore}}%
{\endMakeFramed}
               
\hypersetup{ 
  pdfauthor = {Alberto Ros Bardisa}, 
  pdftitle = {Apuntes de Ampliación de Estructuras de Computadores}, 
  pdfkeywords = {arquitectura de computadores, rendimiento, segmentación, memoria}, 
}

\DeclareTextFontCommand{\c}{\sffamily \slshape}

\setstocksize{297mm}{210mm}
\settrimmedsize{297mm}{210mm}{*}
\setlength{\trimtop}{0pt}
\setlength{\trimedge}{\stockwidth}
\addtolength{\trimedge}{-\paperwidth}
\setlrmarginsandblock{35mm}{25mm}{*}
\setulmarginsandblock{45mm}{50mm}{*}
\setheadfoot{\onelineskip}{3\onelineskip}
\setheaderspaces{*}{1.2\onelineskip}{*}
\checkandfixthelayout

%\parskip 	10pt

\pagestyle{ruled}

\setsecnumdepth{all}

\renewcommand{\topfraction}{1}
\renewcommand{\bottomfraction}{1}
\renewcommand{\textfraction}{0}
\renewcommand{\floatpagefraction}{0}

\makechapterstyle{tesis}{
  \setlength{\beforechapskip}{70pt}
  \renewcommand*{\chapnamefont}{%
    \normalfont\Huge\scshape\raggedleft}
  \renewcommand*{\chaptitlefont}{%
    \normalfont\Huge\bfseries\sffamily\raggedleft}
  \renewcommand*{\afterchapternum}{%
    \par\hspace{1.5cm}\hrule\vskip\midchapskip}
}

\chapterstyle{tesis}

\setsecheadstyle{\Large\bfseries\sffamily\raggedright}
\setsubsecheadstyle{\large\bfseries\sffamily\raggedright}
\setsubsubsecheadstyle{\normalsize\bfseries\sffamily\raggedright}
\setparaheadstyle{\normalsize\bfseries\sffamily}
\setsubparaheadstyle{\normalsize\bfseries\sffamily}

\begin{document}

\hyphenation{ge-ne-ra-dos}

\sloppy
\widowpenalty=10000
\clubpenalty=10000

\title{Apuntes de Ampliación de Estructuras de Computadores}

\author{Alberto Ros Bardisa}

% Begin of title page
\thispagestyle{empty}

\begin{center}

\begin{figure}
\centering
%  \epsfig{file=eps/escudo_universidad,width=6cm}
%  \epsfig{file=eps/escudo.ps,width=6cm,viewport=0 -40 690 639}

  \Large

  %\vspace{1cm}

  \textsc{Universidad de Murcia}

  \large

  Departamento de Ingeniería y \\
  Tecnología de Computadores

  \vspace{3cm}

\end{figure}

\huge

\textbf{Apuntes de\\ Ampliación de Estructura de Computadores}

\vspace{7cm}

\normalsize

Alberto Ros Bardisa

\vspace{0.5cm}

Murcia, septiembre de 2020

\end{center}
% End of title page

\cleardoublepage 

\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}

Estos apuntes pretenden servir como guía para la asignatura
``Ampliación de Estructura de Computadores'' del Grado en Ingeniería 
Informática y Programación Conjunta de Estudios Oficiales Grado
en Matemáticas y Grado en Ingeniería Informática.


\setcounter{chapter}{-1}

\def\figurename{Figura}
\def\tablename{Tabla}
\def\chaptername{Tema}

\chapter{Presentación de la asignatura}
\label{cap:presentacion}

Esta asignatura pertenece al área de ``Arquitectura y Tecnología de
Computadores'' y es la tercera de una serie de asignaturas
obligatorias o troncales del grado de Ingeniería Informática de la
Universidad de Murcia destinadas a comprender cómo funcionan los
computadores y cómo hacerlos más eficientes.

En la primera de estas asignaturas, ``Fundamentos de Computadores'',
se estudia la codificación de la información y los sistemas digitales
combinacionales. En ``Estructura y Tecnología de Computadores'' se
estudian sistemas digitales secuenciales, el diseño de un procesador
básico y la estructura de la jerarquía de memoria. En ``Ampliación de
Estructura de Computadores'' se hace énfasis en el rendimiento del
computador y se estudia un procesador más avanzado (segmentado) que el
visto en la asignatura anterior y aspectos avanzados de la jerarquía
de memoria. Finalmente, en ``Arquitectura y Organización de
Computadores'' se estudian aspectos como el diseño de un procesador
superescalar, la sincronización, el protocolo de coherencia de cachés
y los modelos de consistencia de memoria.

En particular, en ``Ampliación de Estructura de Computadores'' vamos a
ver cómo se pueden mejorar las prestaciones de los computadores por
primera vez en el grado. Hasta el momento nos hemos centrado en tener
un computador que funcione correctamente, sin mirar mucho su
rendimiento. En este curso vamos a construir un ordenador mas potente,
gracias a mejoras ``arquitectónicas''. Se puede decir, por tanto, que
en esta asignatura comienza lo que se conoce por \emph{arquitectura de
  computadores}. No solo vamos a aprender a identificar qué diseño es
mejor que otro de forma ``cualitativa'' sino que también vamos a
aprender a decir de forma ``cuantitativa'' cuantas veces mejor es un
diseño que otro.

La asignatura tiene asignados 6 ECTS. Es decir, se requieren unas 150
horas de trabajo por parte del alumno: 60 de estas horas son
presenciales y están repartidas dos horas de teoría y dos horas de
práctica (un hora y cuarenta minutos en realidad) a la semana, y 90 de
estas horas son no presenciales. Esto último significa que el alumno
debe dedicar unas 90 horas al estudio de la asignatura y realización
de ejercicios. En particular, después de cada sesión el alumno debe
dedicar al rededor de 3 horas más al estudio de la
asignatura. Haciendo esto semanalmente el alumno llevaría la
asignatura al día y sacaría un mayor rendimiento a las horas
presenciales.

\section{Introducción}
\label{sec:introduccion_presentacion}

Las mejoras en el rendimiento de los computadores desde su inicio han
sido debidas tradicionalmente a dos motivos principales: mejoras
debidas a la tecnología y mejoras debidas a la arquitectura. Hasta los
70, las mejoras de ambos eran similares. A partir de los 70 las
mejoras en la tecnología han dominado.

Ley de Moore: Los continuos avances en la escala de integración
permiten reducir el tamaño de los transistores y por tanto el número
de transistores que hay dentro de un chip. El número de transistores
por chip se dobla cada año y medio o dos años.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Análisis de prestaciones en arquitectura de computadores}
\label{cap:prestaciones}


\section{Introducción}
\label{sec:introduccion_prestaciones}

¿Podríamos medir el rendimiento o prestaciones de un computador con un
solo número? En realidad para ser precisos necesitaríamos más de uno,
pero por la necesidad de obtener de forma rápida si un computador
ofrece mejores prestaciones que otro, tratamos de definir las
prestaciones con un solo número. Veremos en este tema que no es una
tarea fácil.

A la hora de usar una métrica para medir el rendimiento debemos llevar
mucho cuidado y saber interpretarla, ya que puede dar lugar a
confusión.

Pongamos un ejemplo. ¿Cómo mediríamos las prestaciones de un coche?
¿Velocidad? Lo importante en realidad no es qué velocidad pueda
alcanzar, sino cuanto tiempo va a tardar en ir de un origen a un destino. Un
coche más rápido que toma una ruta más larga puede tardar más que uno
más lento. Además, no es lo mismo si tenemos un coche con una
capacidad de 5 pasajeros o un autobús con una capacidad de 50. El
autobús, aunque más lento, muy probablemente realice el trabajo de
llevar 100 pasajeros de una ciudad a otra antes que el coche.
Lo que nos interesa en realidad es el trabajo útil que hace el coche
por unidad de tiempo. La clave está en el tiempo.

\section{Definición de rendimiento}

Podemos definir el rendimiento como la cantidad de trabajo realizado
por el computador por unidad de tiempo.

Un ordenador es más rápido que otro cuando realiza la misma cantidad
de trabajo en menor tiempo (disminuye el tiempo de respuesta).

Si estamos interesados en comparar dos computadores respecto al mismo
trabajo, entonces podemos definir rendimiento como la inversa del
tiempo de ejecución.

\[ Rendimiento_{x} = \frac{1}{Tiempo\_de\_ejecuci\acute{o}n_{x}} \]

Para comparar el rendimiento relativo de dos computadores cuando
ejecutan el mismo problema (\emph{speedup} en inglés) diremos que $x$ es un
n\% más rápido que $y$ si:

\[ \emph{Speedup} = \frac{Rendimiento_{x}}{Rendimiento_{y}} = 1 + \frac{n}{100} \]

Por tanto:

\[ \emph{Speedup} = \frac{Rendimiento_{x}}{Rendimiento_{y}} =
\frac{\frac{1}{Tiempo\_de\_ejecuci\acute{o}n_{x}}}{\frac{1}{Tiempo\_de\_ejecuci\acute{o}n_{y}}}
= \frac{Tiempo\_de\_ejecuci\acute{o}n_{y}}{Tiempo\_de\_ejecuci\acute{o}n_{x}} = 1 + \frac{n}{100}\]

\section{Tiempo de ejecución}

El tiempo de ejecución es la mejor métrica para medir el rendimiento.

Tiempo de ejecución de un programa se puede calcular de la siguiente forma:

\[ T_{ej} = NI \times CPI \times T_{c} \]

donde $NI$ representa el número de instrucciones de un programa, $CPI$
son los ciclos por instrucción y $T_{c}$ es el tiempo de ciclo del
computador.

El CPI se puede calcular de la siguiente forma, conociendo cuantos
ciclos tarda de media cada tipo de instrucción ($CPI$) y su frecuencia de
aparición ($f_i$):

\[ CPI = \sum_{i=1}^{n} CPI_i \times f_i \]

\begin{ejercicio}

  \subsection*{Ejercicio}
    
Tenemos la siguiente distribución de instrucciones:

\begin{center}
\begin{tabular}{lrr}
\hline
{\textbf{Tipo}} & {\textbf{Porcentaje}} & {\textbf{Ciclos}} \\
\hline
ALU & 33\% & 2 \\
Load & 21\% & 3 \\
Store & 12\% & 3 \\
Branch & 24\% & 3 \\
FP & 10\% & 12 \\
\hline
\end{tabular}
\end{center}

Sabemos que podemos reducir el número de ciclos de las operaciones
de FP a la mitad, pero ello nos provocará un incremento del ciclo
de reloj del 25\%. Además ahora las cargas consumirán un ciclo
más.

\begin{enumerate}

\item[a)] ¿Cuál de las máquinas es más rápida ahora? ¿En qué factor?.
\item[b)] Si conseguimos no afectar a las cargas con la modificación, ¿varía
el resultado obtenido? ¿Ahora qué máquina es la más rápida? ¿En
qué factor?.

\end{enumerate}

\subsection*{Solución}

Se trata de calcular en ambos casos el tiempo de CPU usando la fórmula explicada en la teoría:
\[ T_{CPU} = NI \times CPI \times T_{ciclo} \]

A partir de los resultados se determina qué máquina es más rápida y se calcula el factor de mejora.

\subsubsection*{Apartado a}

Empezamos por la configuración original (sin aplicar la optimización que describe el enunciado):
\[ T_{CPU\_orig} = NI_{orig} \times CPI_{orig} \times T_{ciclo\_orig} \]

donde $CPI_{orig} = 0.33 \times 2 + 0.21 \times 3 + 0.12 \times 3 + 0.24 \times 3 + 0.10 \times 12 = 3.57$, así pues nos queda que:
\[ T_{CPU\_orig} = NI_{orig} \times 3.57 \times T_{ciclo\_orig} \]

Para la configuración alternativa el tiempo de ciclo se incrementa un 25\% con respecto al original, y los ciclos que tardan las operaciones FP y las cargas se modifican. Tenemos que:
\begin{align*}
  T_{ciclo\_alt} &= 1.25 \times T_{ciclo\_orig}\\
  CPI_{alt} &= 0.33 \times 2 + 0.21 \times 4 + 0.12 \times 3 + 0.24 \times 3 + 0.10 \times 6 = 3.18
\end{align*}

El número de instrucciones no cambia ($NI_{alt} = NI_{orig}$), por lo
que:
\[ T_{CPU\_alt} = NI_{alt} \times 3.18 \times T_{ciclo\_alt} =
NI_{orig} \times 3.18 \times 1.25 \times T_{ciclo\_orig} = \]
\[ = NI_{orig} \times 3.975 \times T_{ciclo\_orig} \]

Por lo tanto, la configuración original es $1.1134$ veces ($3.975 / 3.57$) más rápida que la alternativa propuesta, o lo que es lo mismo: un 11.34\%.

\subsubsection*{Apartado b}

En este caso hay que volver a calcular el CPI de la configuración alternativa teniendo en cuenta que el número de ciclos de las cargas no se ve afectado:
\begin{align*}
CPI_{alt} &= 0.33 \times 2 + 0.21 \times 3 + 0.12 \times 3 + 0.24 \times 3 + 0.10 \times 6 = 2.97 \\
T_{CPU\_alt} &= NI_{orig} \times 2.97 \times 1.25 \times T_{ciclo\_orig} = NI_{orig} \times 3.7125 \times T_{ciclo\_orig}
\end{align*}

La configuración original sigue siendo más rápida, esta vez en un factor 1.04 ($3.7125/3.57$).

\end{ejercicio}

\section{Métricas populares}

MIPS (millones de instrucciones por segundo)

\[ \emph{MIPS} = \frac{NI \times 10^{-6}}{T_{ej}} = \frac{Freq (MHz)}{CPI} \]

es una métrica de
velocidad es fáciles de comprender ya que más MIPS significa más
rápido. Sin embargo tiene una serie de desventajas importantes: Son
dependientes del conjunto de instrucciones, varía entre programas en
el mismo ordenador y puede variar inversamente al rendimiento (por
ejemplo, un computador puede ofecer más MIPS a costa de requerir ejecutar más
instrucciones para realizar la misma tarea que otro programa con menos
instrucciones).

MFLOPS (millones de operaciones de punto flotante por segundo),

\[ \emph{MFLOPS} = \frac{NI P.F. \times 10^{-6}}{T_{ej}} \]

usado
en \url{top500.org}, es otra métrica de velocidad y su principal
ventaja es que el número de instrucciones de punto flotante (P.F.)
depende del algoritmo, no de la máquina. Sin embargo, también tiene una serie
de desventajas: no se pueden aplicar a todos los programas (por
ejemplo un compilador no usa operaciones de punto flotante), todas las
máquinas no tienen las mismas operaciones de punto flotante y todas
las operaciones de punto flotante no tardan lo mismo (por ejemplo una
división tarda mucho más ciclos que una suma).

Volviendo al símil del coche, los kilómetros recorridos por el coche sería el
equivalente al número de instrucciones ejecutadas por el programa.

\section{La Ley de Amdahl}

Imaginemos una aplicación en la que el 80\% del tiempo transcurre
realizando una tarea (T1) y el 20\% restante transcurre realizando otra
tarea (T2).

%\begin{figure}
\begin{center}
  \begin{tikzpicture}
    \draw[draw=white] (0,0.6) rectangle node {80\%} ++(4,0.5);
    \draw[draw=white] (4,0.6) rectangle node {20\%} ++(1,0.5);
    \draw[draw=black,fill=black!20] (0,0) rectangle node {T1} ++(4,0.5);
    \draw[draw=black,fill=black!10] (4,0) rectangle node {T2} ++(1,0.5);
  \end{tikzpicture}
\end{center}
%\end{figure}

Imaginemos también que, con mucho esfuerzo, hemos conseguido eliminar
completamente la necesitad de ejecutar la tarea
T2. ¿Cuál será el \emph{speedup} o mejora del rendimiento de la aplicación?

Si la aplicación antes (llamémosla base) tardaba $x$ segundos y la
aplicación ahora (llamémosla optimizada u opt) tarda 0.8$x$
segundos (un 80\% del tiempo de la aplicación base), entonces tenemos que:

\[ Speedup = \frac{Tiempo_{base}}{Tiempo_{opt}} = \frac{x}{0.8x} =
\frac{1}{0.8} = 1.25 ~ ~ (25\%) \]

Consideremos ahora que en vez de eliminar completamente la tarea T2
hemos conseguido hacerla tan solo el doble de rápido. ¿Cuál será el
\emph{speedup} obtenido en este caso con respecto a la aplicación base?

Si la tarea se ejecuta el doble de
rápido, tardará la mitad del tiempo, y por tanto tenemos:

\begin{center}
  \begin{tikzpicture}
    \draw[draw=white] (0,0.25) node[left] {programa base};
    \draw[draw=white] (0,0.6) rectangle node {80\%} ++(4,0.5);
    \draw[draw=white] (4,0.6) rectangle node {20\%} ++(1,0.5);
    \draw[draw=black,fill=black!20] (0,0) rectangle node {T1} ++(4,0.5);
    \draw[draw=black,fill=black!10] (4,0) rectangle node {T2} ++(1,0.5);
  \end{tikzpicture}
  \begin{tikzpicture}
    \draw[draw=white] (0,0.25) node[left] {programa opt};
    \draw[draw=white] (0,0.6) rectangle node {80\%} ++(4,0.5);
    \draw[draw=white] (4,0.6) rectangle node {10\%} ++(0.5,0.5);
    \draw[draw=black,fill=black!20] (0,0) rectangle node {T1} ++(4,0.5);
    \draw[draw=black,fill=black!10] (4,0) rectangle node {T2} ++(0.5,0.5);
  \end{tikzpicture}
\end{center}

donde el programa optimizado muestra porcentajes relativos al tiempo
del primer programa. El \emph{speedup} en este caso sería:

\[ Speedup = \frac{Tiempo_{base}}{Tiempo_{opt}} = \frac{x}{0.9x} = \frac{1}{0.9} = 1.11 \]

Para calcular este \emph{speedup} hemos hecho uso de la Ley de Amdahl.

La Ley de \href{https://es.wikipedia.org/wiki/Gene_Amdahl}{Amdahl} es una 
fórmula matemática que describe la mejora total en el rendimiento (o \emph{speedup}) de un 
sistema (computador en nuestro caso) con respecto a la mejora de una
fracción de tiempo
de dicho sistema, es decir, si mejoramos una tarea cuya fracción de
tiempo ($f$) se conoce en un factor $S$, la siguiente fórmula nos permite saber el porcentaje de
mejora del sistema.


\begin{center}
  \begin{tikzpicture}
    \draw[draw=white] (0,0.25) node[left] {programa base};
    \draw[draw=white] (0,0.6) rectangle node {$1 - f$} ++(4,0.5);
    \draw[draw=white] (4,0.6) rectangle node {$f$} ++(1,0.5);
    \draw[draw=black,fill=black!20] (0,0) rectangle ++(4,0.5);
    \draw[draw=black,fill=black!10] (4,0) rectangle ++(1,0.5);
  \end{tikzpicture}
  \begin{tikzpicture}
    \draw[draw=white] (0,0.25) node[left] {programa opt};
    \draw[draw=white] (0,0.6) rectangle node {$1 - f$} ++(4,0.5);
    \draw[draw=white] (4,0.6) rectangle node {$f/S$} ++(0.5,0.5);
    \draw[draw=black,fill=black!20] (0,0) rectangle ++(4,0.5);
    \draw[draw=black,fill=black!10] (4,0) rectangle ++(0.5,0.5);
  \end{tikzpicture}
\end{center}

\[ Speedup = \frac{Tiempo_{base}}{Tiempo_{opt}} = \frac{(1 - f) +
  f}{(1 - f) + \frac{f}{S}} = \frac{1}{(1 - f) + \frac{f}{S}} \]

\begin{center}
\framebox{$Speedup = \frac{1}{(1 - f) + \frac{f}{S}}$}
\end{center}
  
Por ejemplo, si en un procesador conseguimos mejorar las instrucciones en coma flotante para
que se ejecuten el doble de rápidas,
pero el procesador ejecuta una aplicación que solo dedica un 10\% de su tiempo a ejecutar estas
instrucciones podemos aplicar la Ley de Amdahl, ya que sabemos el
porcentaje de tiempo de la parte mejorada (10\% del total) y sabemos
en qué factor estamos mejorando (el doble, o sea un factor de 2).

\[ Speedup = \frac{1}{(1 - f) + \frac{f}{S}} = \frac{1}{(1 - 0.1) +
  \frac{0.1}{2}} = 1.053 ~ ~ (5.3\%) \]

Cabe destacar que la mejora podría cambiar al ejecutar otra aplicación
ya que el porcentaje del tiempo que dedica a las instrucciones de coma
flotante puede variar.

\begin{ejercicio}

\subsection*{Ejercicio}

Supongamos que se puede mejorar la velocidad de la CPU
de nuestra máquina en un factor de cinco (sin afectar al
rendimiento de la E/S) por cinco veces el coste. Supongamos
también que la CPU se utiliza el 50\% del tiempo, y que el tiempo
restante la CPU está esperando las operaciones de E/S. ¿Cuánto se
incrementa el rendimiento total? Si la CPU supone un tercio del 
coste total de la máquina, ¿cuánto se incrementa el coste total? 
Por tanto, ¿el incremento de la velocidad de la CPU en un factor 
de cinco es una buena inversión desde un punto de vista 
coste/rendimiento?

\subsection*{Solución}

Inicialmente, la relación coste/rendimiento de la máquina es $C/R$. Vamos a calcular cómo se incrementa el rendimiento por un lado y el coste por otro con el cambio. Si el rendimiento se incrementa en mayor medida que el coste, o ambos aspectos se ven mejorados en igual proporción, entonces el cambio es interesante desde el punto de vista de la relación coste/rendimiento. Si el coste se incrementa en mayor medida que el rendimiento, entonces el cambio no es aconsejable.

Para calcular la mejora en el rendimiento que se obtiene con el cambio aplicamos la Ley de Amdahl, considerando que la CPU se usa el 50\% del tiempo: 

\[\emph{Speedup} = \frac{1}{1-0.5 + 0.5/5} = 1.667\]

Lo que significa que el rendimiento tras el cambio $R' = 1.667 \times R$.

Por otro lado, la CPU supone $1/3$ del coste del sistema y se ha multiplicado por 5 su precio, con lo que el coste tras el cambio $C' = 2/3 \times C + 1/3 \times C \times 5 = 7/3 \times C = 2.334 \times C$

Concluimos, pues, que el cambio no es interesante, ya que el coste se incrementa en mayor proporción que el rendimiento (incremento de 2.334 veces en el coste para obtener un factor de mejora en el rendimiento de 1.667).

\end{ejercicio}

\section{Cómo obtener el rendimiento medio}

En esta sección veremos como obtener el rendimiento medio cuando
ejecutamos varias aplicaciones que ofrecen diferentes prestaciones dependiendo de la máquina donde se
ejecuten.

Imaginemos, por ejemplo, que tenemos dos computadores ($A$ y $B$) y
dos aplicaciones ($1$ y $2$) que usamos
para evaluar el rendimiento de los computadores. Al ejecutar las
aplicaciones en ambos computadores obtenemos los siguientes tiempos:

\begin{center}
\begin{tabular}{ccc}
\hline
  & Computador $A$ & Computador $B$ \\ 
\hline
 Aplicación 1 & 10 segundos & 2 segundos \\  
 Aplicación 2 & 20 segundos & 60 segundos \\
 \hline
\end{tabular}
\end{center}

¿Qué computador obtiene mejor rendimiento?
Para tomar esta decisión se podría obtener la media del rendimiento de las aplicaciones
para cada computador, pero hay que tener mucho cuidado con qué media
es mejor usar en cada caso.

\subsection{Media aritmética}

La media aritmética equivale a usar para obtener el rendimiento la
suma de los tiempos de ejecución de todas las aplicaciones.

Para obtener la media aritmética usaríamos la siguiente fórmula:

\[ Media\_aritm\acute{e}tica = \sum_{i=1}^{n} \frac{tiempo_i }{n} \]

Esta media es adecuada cuando disponemos de los tiempos de cada
programa pero no sabemos con qué frecuencia se va a ejecutar cada uno.

En el ejemplo anterior, la media aritmética para el computador $A$ y
$B$ sería:

\begin{center}
\begin{tabular}{ccc}
\hline
  & Computador $A$ & Computador $B$ \\ 
\hline
 Aplicación 1 & 10 segundos & 2 segundos \\  
 Aplicación 2 & 20 segundos & 60 segundos \\
 \hline
 Media aritmética & 15 segundos & 31 segundos \\
 \hline
\end{tabular}
\end{center}

Por tanto, podríamos decir que el computador $A$ es
$\frac{31}{15}=2.07$ veces más rápido que el computador $B$.

\subsection{Media aritmética ponderada}

No todos los programas se ejecutan el mismo número de veces en una
máquina. Si supiéramos la frecuencia de ejecución de cada programa,
podríamos obtener una mejor medida del rendimiento del computador
aplicando media aritmética ponderada:

\[ Media\_aritm\acute{e}tica\_ponderada = \sum_{i=1}^{n} w_i \times tiempo_i \]

donde $w_i$ es el ratio de ejecución de cada aplicación.

Imaginemos ahora que sabemos que la aplicación 1 se va a ejecutar un
10\% de las veces y la aplicación 2 el 90\% restante.

En ese caso podríamos calcular la media aritmética ponderada:

\begin{center}
\begin{tabular}{ccc}
\hline
  & Computador $A$ & Computador $B$ \\ 
\hline
 Aplicación 1 (w = 0.1) & 10 segundos & 2 segundos \\  
 Aplicación 2 (w = 0.9) & 20 segundos & 60 segundos \\
 \hline
 Media aritmética ponderada & 19 segundos & 54.2 segundos \\
 \hline
\end{tabular}
\end{center}

Podríamos decir en este caso que el computador $A$ es
$\frac{54.2}{19}=2.85$ veces más rápido que el computador $B$.

Si por el contrario la aplicación 1 se ejecutara un
90\% de las veces y la aplicación 2 el 10\% restante, la media
aritmética ponderada quedaría como:

\begin{center}
\begin{tabular}{ccc}
\hline
  & Computador $A$ & Computador $B$ \\ 
\hline
 Aplicación 1 (w = 0.9) & 10 segundos & 2 segundos \\  
 Aplicación 2 (w = 0.1) & 20 segundos & 60 segundos \\
 \hline
 Media aritmética ponderada & 11 segundos & 7.8 segundos \\
 \hline
\end{tabular}
\end{center}

En este caso deberíamos decir que el computador $B$ es
$\frac{11}{7.8}=1.41$ veces más rápido que el computador $A$.

Como vemos el rendimiento puede cambiar dependiendo de la frecuencia
de ejecución de los programas.

\subsection{Media geométrica}
\label{sec:media_geometrica}

A veces es interesante normalizar los resultados obtenidos, con el fin
de que una aplicación que tarda mucho más que otra no tenga
necesariamente más peso en la media final.

Normalizar significa dividir los resulatados de las aplicaciones por
los obtenidos por dichas aplicaciones en una máquina de referencia.

Por ejemplo, podemos normalizar los resultados anteriores respecto al
computador $A$, dividiendo todos los tiempo por los obtenidos por el
computador $A$:

\begin{center}
\begin{tabular}{ccccc}
\hline
  & Computador $A$ & Computador $B$ & Norm $A$(/$A$) & Norm $B$(/$A$) \\ 
\hline
Aplicación 1 & 10 segundos & 2 segundos & 1 & 0.2 \\  
Aplicación 2 & 20 segundos & 60 segundos & 1 & 3 \\
\hline
\end{tabular}
\end{center}

Cuando tenemos números normalizados no podemos usar la media
aritmética ya que puede ser engañosa: dependiendo de la máquina de
referencia (para la que normalizamos) el resultado puede ser que una
máquina es mejor o que la otra es mejor.

Por tanto, cuando tengamos números normalizados debemos utilizar la
media geométrica, ya que ofrecerá un resultado independiente del
computador que usemos para normalizar.

\[ Media\_geom\acute{e}trica = \sqrt[n]{\prod_{i=1}^{n} tiempo\_normalizado_i} \]

Veámoslo con el ejemplo normalizado respecto al computador $A$:

\begin{center}
\begin{tabular}{ccccc}
\hline
  & Computador $A$ & Computador $B$ & Norm $A$(/$A$) & Norm $B$(/$A$) \\ 
\hline
Aplicación 1 & 10 segundos & 2 segundos & 1 & 0.2 \\  
Aplicación 2 & 20 segundos & 60 segundos & 1 & 3 \\
\hline
\multicolumn{2}{l}{Media aritmética} &  & 1 & 1.6 \\
\hline
\multicolumn{2}{l}{Media geométrica} &  & 1 & 0.77 \\
\hline
\end{tabular}
\end{center}

En este caso la media aritmética me indica que el computador $A$ es
más rápido que $B$ pero la media geométrica me indica que el
computador $B$ es $\frac{1}{0.77}=1.29$ veces más rápido que $A$.

Vemos ahora qué sucede si normalizamos con respecto al computador $B$:

\begin{center}
\begin{tabular}{ccccc}
\hline
  & Computador $A$ & Computador $B$ & Norm $A$(/$B$) & Norm $B$(/$B$) \\ 
\hline
Aplicación 1 & 10 segundos & 2 segundos & 5 & 1 \\  
Aplicación 2 & 20 segundos & 60 segundos & 0.33 & 1 \\
\hline
\multicolumn{2}{l}{Media aritmética} &  & 2.67 & 1 \\
\hline
\multicolumn{2}{l}{Media geométrica} &  & 1.29 & 1 \\
\hline
\end{tabular}
\end{center}

En este caso, mientras que la media geométrica me sigue diciendo que
el computador $B$ es 1.29 veces más rápido que el computador $A$,
ahora la media aritmética cambia y está deacuerdo con la geométrica en
que el computador $B$ es más rápido que el computador $A$.

\subsection{Media armónica}

Cuando en vez de tiempos de ejecución dispongamos de velocidades o
frequencias, como
es el caso de métricas como MIPS y MFLOPS, no debemos usar la media
aritmética.

Pongamos de nuevo el ejemplo de un coche que tiene que hacer un
recorrido esta vez de ida y vuelta. Si el coche viaja a la ida a
50km/h y a la vuetla a 100km/h, ¿a qué velocidad media ha ido?
Definitivamente no es 75km/h, por que el tiempo que tarda en ir y en
volver no es el mismo.

Para calcular la media en este caso aplicaríamos la media armónica.

\[ Media\_arm\acute{o}nica = \frac{n}{\sum_{i=1}^{n} \frac{1}{velocidad_i}} \]

Y el resultado sería la velocidad media del coche: 66.67km/h

La misma media deberíamos aplicar si tenemos MIPS o MFLOPS, ya que son
métricas de velocidad.

\subsection{Media armónica ponderada}

Si tuviéramos información sobre las veces que se va a ejecutar cada
programa y la velocidad de cada uno en cada computador, entonces deberíamos usar la media armónica ponderada:

\[ Media\_arm\acute{o}nica\_ponderada = \frac{n}{\sum_{i=1}^{n} \frac{w_i}{velocidad_i}} \]

Nota: Números de velocidad normalizados se deberán calcular con la
media geométrica por las razones explicadas en la
sección~\ref{sec:media_geometrica}.

\section{Programas de prueba (benchmarks)}

Los benchmarks son programas de prueba que sirven como instrumento para medir el rendimiento de un sistema o de sus componentes. 

Estos programas de prueba pueden ser diseñados específicamente para
medir cualquiera de los componentes del sistema, ya sea la CPU,
tarjeta grafica, RAM, etc.

Existen distintos tipos de benchmarks con sus ventajas e inconvenientes:

\begin{itemize}

\item Aplicaciones reales: aunque son las más precisas a la hora de
  obtener el rendimiento, pueden tener problemas de portabilidad.

\item Aplicaciones modificadas: solucionan los problemas de
  portabilidad de las aplicaciones reales y se centran en un aspecto
  concreto del sistema.
  
\item Nucleos (kernels): son pequeñas partes de cruciales de programas reales, que se
  ejecutan frecuentemente.

\item Benchmarks reducidos (toys): Son benchmarks pequeños y
  fácilmente portables, aunque poco útiles para evaluar el rendimiento.

\item Benchmarks sintéticos: si objetivo es obtener un perfil medio de
  ejecución, por ejemplo se puede indicar cuantas operaciones de
  lectura el programa va a tener. No son adecuados para
  obtener medidas de rendimiento fiables.

\end{itemize}

Existen algunos conjuntos de aplicaciones (o benchmark suites) usados ampliamente para evaluar
prestaciones:

\begin{itemize}

\item SPEC (Standard Performance Evaluation Coorporation): Tiene como
  objetivo crear un benchmark estándar para medir el rendimiento de
  computadores y controlar los resultados de los tests realizados, que
  posteriormente se hacen publicos. Principalmente enfocado en medir
  el rendimiento de la CPU.

\item TPC (Transaction Processing Council): Modelan usuarios que
  ejecutan transacciones en una base de datos. El TPC mide la rapidez
  y fiabilidad con la que se realizan dichas transacciones. La unidad
  de medida son transacciones por minuto o segundo.

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Segmentación básica}
\label{cap:segmentado}


\section{Introducción}
\label{sec:introduccion_segmentado}

Concepto de segmentación. Segmentación para la ejecución de
instrucciones: camino de datos y control segmentado. Riesgos de la
segmentación (estructurales, de datos y de control). Excepciones y su
implementación.

\subsection{El juego de instrucciones DLX}

Repaso de instrucciones. Remarcar diferencias con MIPS (ETC): blt -> slt \& beqz

\subsection{Procesador multiciclo para DLX}

Repaso de etapas multiciclo (ETC), pero adaptado a DLX. Ejemplo de
un load, que es el más largo (5 ciclos). El resto de instrucciones se adaptan a éste. 

\section{Segmentación para la ejecución de instrucciones}

Describir segmentación a grandes rasgos, o de forma esquemática. Los
detalles de implementación se verán al final.

Ejercicio cuantitativo de segmentación.

\section{Problemas de la segmentación: los riesgos}

Si tuvieramos una fábrica de coches la segmentación ya funcionaría
bien y tendríamos un cauce ideal, produciendo un coche por tiempo de
cada etapa.

Pero las instrucciones son más complicadas. No todas son iguales. Y la
ejecución de una puede depender de la otra.

Hay 3 tipos de riesgos: estructurales, de datos y de control. 

\subsection{Riesgos estructurales}

Opciones: duplicar, parar, evitar sw (separar o nops).

\subsection{Riesgos de datos}

Opciones: parar, forwarding, evitar sw (separar o nops).

\subsection{Riesgos de control}

Opciones: parar, adelantar calculo salto, predecir, evitar sw (delay-slot o nops).

Detalle de la implementación. ¿Cómo parar ante riesgos (y adelantar el
calculo del salto)?

Ejercicios de delay en calculo de tiempo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Segmentación avanzada y predicción de saltos}
\label{cap:avanzada}


\section{Introducción}
\label{sec:introduccion_avanzada}

Mitigación de los riesgos de datos: adelantamientos. Mitigación de los riesgos de control (predicción de saltos estática y predicción de saltos dinámica). Segmentación DLX de punto flotante. Cauces con terminación fuera de orden.

\section{Predicción de saltos}

Observación 1: los saltos tienden a tener el mismo comportamiento.

Observación 2: saltos correlacionados.

\subsection{Estática}

Algo más sobre predicción estática saltos para alante o para atrás o comparación == 0 o != 0.

\subsection{Contador saturado por salto}

Ejemplo: bucle.

Aliasing.

\subsection{Correlación}

ejemplo: if d == 0
ejemplo: found = find(elem); if (found) ...  if a[i] = elem.

historia global.

gshare.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Sistema de memoria de altas prestaciones}
\label{cap:memoria}


\section{Introducción}
\label{sec:introduccion_memoria}

Introducción a los sistemas de memoria. Diseño de una jerarquía de caches de alto rendimiento: reducción de la tasa de fallos,  reducción de la penalización por fallo y reducción del tiempo de acierto en caches. Organizaciones de la memoria principal. Memoria virtual. Técnicas de traducción rápida de direcciones virtuales. Protección de memoria.

\section{Evaluación del Rendimiento de la Jerarquía de Memoria}

\section{Reducción de la Tasa de Fallos de Caché}

\subsection{Clasificación de fallos de caché}

Podemos distinguir los siguientes motivos por los que se 
producen fallos en caché:

Forzosos: el primer acceso a un bloque de memoria no puede 
estar en la caché (poco efecto en programas grandes)
- Llamados fallos de arranque en frío o de primera referencia

Capacidad: la memoria caché no tiene el tamaño suficiente para 
contener todos los bloques necesarios
- En un momento determinado uno de los bloques que se han 
utilizado tiene que dejar hueco a otro (la caché está llena)
- Se produce fallo si se vuelve a referenciar el bloque desalojado

Conflicto: la memoria caché no es totalmente asociativa 
- Aciertos en una caché totalmente asociativa que se vuelven 
fallos en una asociativa por conjuntos de 
n-vías se deben a más de n peticiones sobre algunos conjuntos

\subsection{Optimizaciones hardware}

\subsubsection{Aumento del tamaño de bloque}

Y del tamaño de la caché. De hecho la primera figura (pag 29) lo contempla.

\subsubsection{Aumento de la asociatividad}

\subsubsection{Caché de víctimas}

\subsubsection{Búsqueda anticipada de datos e instrucciones (prefetching)}

\subsection{Optimizaciones del compilador}

\subsubsection{Combinación de arrays (merging arrays)}

\subsubsection{Intercambio de iteraciones (loop exchange)}

\subsubsection{Unión de bucles (loop fusion)}

\subsubsection{Blocking}

\subsubsection{Búsqueda anticipada}


\section{Reducción de la Penalización por Fallo de Caché}

\section{Reducción del Tiempo en Caso de Acierto en Caché}

\section{Organizaciones de la Memoria Principal}

\bibliographystyle{plain} 
\bibliography{bibliografia} 

\end{document} 
